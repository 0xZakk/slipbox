- **Type:** #[[__ üü¶  Reference Note]] #[[üì• Inbox]] #[[üìù To Process]] | [[Mental Model]]
- **Source:**  twitter
- **Author:** @G_S_Bhogal on Twitter
- **Summary:**
- ### Highlights first synced by [[Readwise]] [[November 24th, 2020]]
    - MEGATHREAD TIME: In 40 tweets I will describe 40 powerful concepts for understanding the world. Some are complex so forgive me for oversimplifying, but the main purpose is to incite curiosity. Okay, here we go: 
    - Causal Reductionism: Things rarely happen for just 1 reason. Usually, outcomes result from many causes conspiring together. But our minds cannot process such a complex arrangement, so we tend to ascribe outcomes to single causes, reducing the web of causality to a mere thread. 
    - Ergodicity: A die rolled 100 times has equal probabilities to 100 dice rolled once; rolling a die is ‚Äúergodic‚Äù. But if the die gets chipped after 10 throws so it‚Äôs likelier to roll 4, then 1 die 100 times =/= 100 dice once (non-ergodic). Many treat non-ergodic systems as ergodic. 
    - Dunning-Kruger Effect: Awareness of the limitations of cognition (thinking) requires a proficiency in metacognition (thinking about thinking). In other words, being stupid makes you too stupid to realize how stupid you are. 
    - Emergence: When many simple objects interact with each other, they can form a system that has qualities that the objects themselves don‚Äôt. Examples: neurons creating consciousness, traders creating the stock-market, simple mathematical rules creating ‚Äúliving‚Äù patterns. https://t.co/3lPd3JEhuB 
    - Cultural Parasitism: An ideology parasitizes the mind, changing the host‚Äôs behavior so they spread it to other people. Therefore, a successful ideology (the only kind we hear about) is not configured to be true; it is configured only to be easily transmitted and easily believed. 
    - Cumulative Error: Mistakes grow. Beliefs are built on beliefs, so one wrong thought can snowball into a delusional worldview. Likewise, as an inaccuracy is reposted on the web, more is added to it, creating fake news. In our networked age, cumulative errors are the norm. 
    - Survivorship Bias: We overemphasize the examples that pass a visibility threshold e.g. our understanding of serial killers is based on the ones who got caught. Equally, news is only news if it‚Äôs an exception rather than the rule, but since it‚Äôs what we see we treat it as the rule 
    - Simpson‚Äôs Paradox: A trend can appear in groups of data but disappear when these groups are combined. This effect can easily be exploited by limiting a dataset so that it shows exactly what one wants it to show. Thus: beware of even the strongest correlations. https://t.co/O34Or7V5rN 
    - Condorcet Paradox: a special instance of Simpson‚Äôs paradox applied to elections, in which a populace prefers candidate A to candidate B, candidate B to C, and yet candidate C to A. This occurs because the majority that favors C is misleadingly divided among different groups. 
    - Limited Hangout: A common tactic by journos & politicians of revealing intriguing but relatively innocent info to satisfy curiosity and prevent discovery of more incriminating info. E.g. a politician accused of snorting cocaine may confess to having smoked marijuana at college. 
    - Focusing Illusion: Nothing is ever as important as what you‚Äôre thinking about while you‚Äôre thinking about it. E.g. worrying about a thing makes the thing being worried about seem worse than it is. As Marcus Aurelius observed, ‚ÄúWe suffer more often in imagination that in reality.‚Äù 
    - Concept Creep: As a social issue such as racism or sexual harassment becomes rarer, people react by expanding their definition of it, creating the illusion that the issue is actually getting worse. I explain the process in detail here: https://t.co/hG2Erq1y96 
    - Streetlight Effect: People tend to get their information from where it‚Äôs easiest to look. E.g. the majority of research uses only the sources that appear on the first page of Google search results, regardless of how factual they are. Cumulatively, this can skew an entire field. 
    - Belief Bias: Arguments we'd normally reject for being idiotic suddenly seem perfectly logical if they lead to conclusions we approve of. In other words, we judge an argument‚Äôs strength not by how strongly it supports the conclusion but by how strongly *we* support the conclusion. 
    - Pluralistic Ignorance:  Phenomenon where a group goes along with a norm, even though all of the group members secretly hate it, because each mistakenly believes that the others approve of it. (See also: Abilene Paradox) 
    - The Petrie Multiplier: In fields in which men outnumber women, such as in STEM, women receive an underestimated amount of harassment due to the fact that there are more potential givers than receivers of harassment. (See also: Lotka‚ÄìVolterra equations) https://t.co/ufCSQqAC0m 
    - Woozle Effect: An article makes a claim without evidence, is then cited by another, which is cited by another, and so on, until the range of citations creates the impression that the claim has evidence, when really all articles are citing the same uncorroborated source. 
    - Tocqueville Paradox: As the living standards in a society rise, the people‚Äôs expectations of the society rise with it. The rise in expectations eventually surpasses the rise in living standards, inevitably resulting in disaffection (and sometimes populist uprisings). 
    - Ultimate Attribution Error: We tend to attribute good acts by allies to their character, and bad acts by allies to situational factors. For opponents, it‚Äôs reversed: good acts are attributed to situational factors, and bad acts to character. 
    - Golden Hammer: When someone, usually an intellectual who has gained a cultish following for popularizing a concept, becomes so drunk with power he thinks he can apply that concept to everything. Every mention of this concept should be accompanied by a picture of @nntaleb. https://t.co/V4fMpZVWfX 
    - Pareto Principle: Pattern of nature in which ~80% of effects result from ~20% of causes. E.g. 80% of wealth is held by 20% of people, 80% of computer errors result from 20% of bugs, 80% of crimes are committed by 20% of criminals, 80% of box office revenue comes from 20% of films 
    - Nirvana Fallacy: When people reject a thing because it compares unfavorably to an ideal that in reality is unattainable. E.g. condemning capitalism due to the superiority of imagined socialism, condemning ruthlessness in war due to imagining humane (but unrealistic) ways to win. 
    - Emotive Conjugation: Synonyms can yield positive or negative impressions without changing the basic meaning of a word. Example: someone who is obstinate (neutral term) can be ‚Äúheadstrong‚Äù (positive) or ‚Äúpig-headed‚Äù (negative). This is the basis for much bias in journalism. 
    - Anentiodromia: An excess of something can give rise to its opposite. E.g. A society that is too liberal will be tolerant of tyrants, who will eventually make it illiberal. I explain more here: https://t.co/oGv498JLnZ 
    - Halo Effect: When a person sees an agreeable characteristic in something or someone, they assume other agreeable characteristics. Example: if a Trump supporter sees someone wearing a MAGA cap, he‚Äôs likely to think that person is also decent, honest, hard-working, etc. 
    - Outgroup Homogeneity Effect: We tend to view outgroup members as all the same e.g. believing all Trump supporters would see someone wearing a MAGA cap, and think that person is also decent, honest, hard-working, etc. 
    - Matthew Principle: Advantage begets advantage, leading to social, economic, and cultural oligopolies. The richer you are the easier it is to get even richer, the more recognition a scientist receives for a discovery the more recognition he‚Äôll receive for future discoveries, etc. 
    - Peter Principle: People in a hierarchy such as a business or government will be promoted until they suck at their jobs, at which point they will remain where they are. As a result, the world is filled with people who suck at their jobs. 
    - Loki‚Äôs Wager: Fallacy where someone tries to defend a concept from criticism, or dismiss it as a myth, by unduly claiming it cannot be defined. E.g. ‚ÄúGod works in mysterious ways‚Äù (god of the gaps), ‚Äúrace is biologically meaningless‚Äù (Lewontin‚Äôs fallacy). https://t.co/zKtZhRrj8K 
    - Subselves: We use different mental processes in different situations, so each of us is not a single character but a collection of different characters, who take turns to commandeer the body depending on the situation. There is an office ‚Äúyou‚Äù, a lover ‚Äúyou‚Äù, an online ‚Äúyou‚Äù, etc. 
    - Goodhart‚Äôs Law: When a measure becomes a goal, it ceases to become a measure. E.g. British colonialists tried to control snakes in India. They measured progress by number of snakes killed, offering money for snake corpses. People responded by breeding snakes & killing them. 
    - Radical Phase Transition (my term): Extremist movements can behave like solids (tyrannies), liquids (insurgencies), and gases (conspiracy theories). Pressuring them causes them to go from solid => liquid => gas. Leaving them alone causes them to go from gas => liquid => solid. 
    - Legibility: We see a complex natural system, assume that because it *looks* messy that it must be disordered, then impose our own order on it to make it ‚Äúlegible‚Äù. But in removing the messiness we remove essential components of the system that we couldn‚Äôt grasp, and it fails. https://t.co/LQqvpkFcMp 
    - Shifting Baseline Syndrome: 
Frog says to Fish, ‚Äúhow‚Äôs the water?‚Äù 
Fish replies, ‚Äúwhat‚Äôs water?‚Äù 
We become blind to what we‚Äôre familiar with. And since the world is always changing, and we're always getting used to it, we can even become blind to the slow march of catastrophe. 
    - Availability Cascade: When a new concept enters the arena of ideas, people react to it, thereby amplifying it. The idea thus becomes more popular, causing even more people to amplify it by reacting to it, until everyone feels the need to talk about it. 
    - Gurwinder Principle: It is often necessary to eat chocolate cake. 
    - Reactance Theory: When someone is restricted from expressing a POV, or pressured to adopt a different POV, they usually react by believing their original POV even more. For a detailed example read my piece on my attempt to deradicalize a neo-Nazi: https://t.co/30qw0616H7 
    - Predictive Coding: There is no actual movement on a TV screen; your brain invents it. There are no actual spaces between spoken words; your brain inserts them. Human perception is like predictive text, replacing the unknown with the expected.

Predictive Coding leads to‚Ä¶ 
    - Apophenia: We impose our imaginations on arrangements of data, seeing patterns where no such patterns exist. 

A common form of Apophenia is‚Ä¶ 
    - Narrative Fallacy: When we see a sequence of facts we interpret them as a story by threading them together into an imagined chain of cause & effect. If a drug addict commits suicide we assume the drug habit led to the suicide, even if it didn‚Äôt.

Another form of Apophenia is‚Ä¶ 
    - Pareidolia: For aeons predators stalked us in undergrowth & shadow. In such times survival favored the paranoid‚Äîthose who could discern a wolf from the vaguest of outlines. This paranoia preserved our species, but cursed us with pareidolia, so we now see wolves even in the skies. https://t.co/9pxdCZ4MrN 
    - And that‚Äôs it! There are many other ideas but these are the ones that came to mind first (availability bias), and I think they provide good springboards for understanding a wide range of phenomena. Feel free to reply with your own, and see if you can explain them in 1 tweet! 
